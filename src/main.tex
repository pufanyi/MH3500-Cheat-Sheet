\documentclass[9pt,landscape]{article}

\usepackage{multicol}
\usepackage{amsmath}

\input{format.tex} % formatting template

\begin{document}

\begin{multicols}{3}

\columnseprule=0.25pt

\section{公式}

$\mathrm{Var}(X)=\mathbb{E}(X^2)-(\mathbb{E}(X))^2$

$\sum_{k=1}^{n}k^3=\frac{1}{4}n^2(n+1)^2$

$\sum_{k=0}^{n-1}r^k=\frac{1-r^n}{1-r}, r\neq 1$

$\sum_{k=1}^{n}kr^k=r\frac{1-(n+1)r^n+nr^{n+1}}{(1-r)^2}, r\neq 1$

$\sin x = \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)!}x^{2n+1} = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \cdots$

$\cos x = \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n)!}x^{2n} = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \cdots$

$\ln x = \sum_{n=1}^{\infty} \frac{(-1)^{n-1}}{n}(x-1)^n = (x-1) - \frac{(x-1)^2}{2} - \cdots$

$\frac{1}{1-x} = \sum_{n=0}^{\infty} x^n = 1 + x + x^2 + x^3 + \cdots$

$\frac{\mathrm{d}}{\mathrm{d}x}\tan x=\sec ^{2}x$

$\frac{\mathrm{d}}{\mathrm{d}x}\cot x=-\csc ^{2}x$

$\frac{\mathrm{d}}{\mathrm{d}x}\sec x=\sec x\tan x$

$\frac{\mathrm{d}}{\mathrm{d}x}\csc x=-\csc x\cot x$

$\frac{\mathrm{d}}{\mathrm{d}x}\arcsin x={\frac {1}{\sqrt {1-x^{2}}}}$

$\frac{\mathrm{d}}{\mathrm{d}x}\arccos x=-{\frac {1}{\sqrt {1-x^{2}}}}$

$\frac{\mathrm{d}}{\mathrm{d}x}\arctan x={\frac {1}{1+x^{2}}}$

$ \int {\frac {1}{x^{2}+\alpha ^{2}}}{\mbox{d}}x={\frac {\arctan {\frac {x}{\alpha }}}{\alpha }} $

$ \int {\frac {1}{\pm x^{2}\mp \alpha ^{2}}}{\mbox{d}}x={\frac {\ln \left({\frac {x\mp \alpha }{\pm x+\alpha }}\right)}{2\alpha }} $

$ \int {\frac {1}{ax^{2}+b}}{\mbox{d}}x={\frac {1}{\sqrt {ab}}}\arctan {\frac {{\sqrt {a}}x}{\sqrt {b}}} $

$ \int {\frac {1}{\sqrt {a^{2}-x^{2}}}}{\mbox{d}}x=\arcsin {\frac {x}{a}}=-\arccos {\frac {x}{a}} $

$ \int \sec ^{2}x{\mbox{d}}x=\tan x $

$ \int \csc ^{2}x{\mbox{d}}x=-\cot x $

$ \int \sec x\tan x{\mbox{d}}x=\sec x $

$ \int \csc x\cot x{\mbox{d}}x=-\csc x $

$ \int \tan x{\mbox{d}}x=-\ln {\left|\cos {x}\right|}=\ln {\left|\sec x\right|} $

$ \int \cot x{\mbox{d}}x=\ln {\left|\sin x\right|} $

$ \int \sec x{\mbox{d}}x=\ln {\left|\sec x+\tan x\right|} $

$ \int \csc x{\mbox{d}}x=\ln {\left|\csc x-\cot x\right|}=\ln {\left|{\tan x-\sin x \over \sin x\tan x}\right|} $

$ \int x^{n}e^{ax}{\mbox{d}}x={\frac {1}{a}}x^{n}e^{ax}-{\frac {n}{a}}\int x^{n-1}e^{ax}{\mbox{d}}x $

$ \int _{-\infty }^{\infty }e^{-ax^{2}+bx+c}\,\mathrm{d}x={\sqrt {\frac {\pi }{a}}}\,e^{{\frac {b^{2}}{4a}}+c} $


\section{Probability}

\subsection{Distribution}

\textbf{Poisson Distribution}

本质上是一个$n\to\infty$的二项分布，$\lambda=np$。

性质：$\mathbb{E}(X)=\lambda,\text{Var}(X)=\lambda$

Approximate Bin: $n$ large, $p$ small ($n \ge 50, np \le 5$)

\textbf{Hypergeometric Distribution}

记号：$X \sim \text{Hypergeomet}(n, N, m)$

概率：$p(k)=\frac{\binom{m}{k}\binom{N-m}{n-k}}{\binom{N}{n}}$

$N$ 个球，$m$ 个红球，不放回取出 $n$ 个，有 $k$ 红球。

$\mathbb{E}(X)=n\cdot\frac{m}{N}, \mathrm{Var}(X)=n\cdot \frac{m}{N}\left(1-\frac{m}{N}\right)\left(1-\frac{n-1}{N-1}\right)$

\textbf{Normal Distribution}

Approximate Bin: $np(1-p)\ge 10$

$Z\sim N(0, 1), \mathbb{E}(g'(Z))=\mathbb{E}(Zg(Z))$,  assuming that $\lim_{x\to \infty}\frac{g(x)}{e^{\frac{x^2}{2}}}=0$. So $\mathbb{E}(Z^{n+1})=n\mathbb{E}(Z^{n-1})$.

\textbf{Exponential Distribution}

CDF：$F(X)=1-e^{-\lambda x}, x\ge 0$

$\mathbb{P}r(X>x)=e^{-\lambda x}, x\ge 0$

$\mathbb{E}(X^n)=\frac{n}{\lambda}\mathbb{E}(X^{n-1})=\frac{n!}{\lambda^n}$

$\mathbb{E}(X)=\frac{1}{\lambda}, \mathrm{Var}(X)=\frac{1}{\lambda^2}$

\textbf{Gamma Distribution}

考试都用 $\Gamma(\alpha, \beta)$ 的形式

$\Gamma(x)=\int_{0}^{\infty}u^{x-1}e^{-u}\mathrm{d}u, x>0$

$\Gamma(x)=(x-1)\Gamma(x - 1)$

$\Gamma(n)=(n-1)!$

$\alpha$：发生次数

$\mathbb{E}(X)=\alpha\beta, \mathrm{Var}(X)=\alpha\beta^2$

$\mathbb{E}(X^n)=(n+\alpha-1)\beta\cdot\mathbb{E}(X^{n-1})=\alpha^{\overline{n}}\beta^n$

\textbf{Chi-Squared Distribution}

$X\sim \chi^2(k)$

$\mathbb{E}(X)=k$

$\mathcal{N}(0, 1)^2\sim \chi^2_1$

$\chi^2_n\sim \Gamma\left(\frac{n}{2}, 2\right)$

$\frac{1}{\sigma^2}\sum (X_i-\mu)\sim\chi^2_n$

$\frac{1}{\sigma^2}\sum (X_i-\overline{X})\sim\chi^2_{n-1}$

\textbf{$t$-Distribution}

$T_k = \frac{C}{\sqrt{D/k}}, C\sim\mathcal{N}(0, 1), D = \chi^2_k$

$\frac{\sqrt{n}(\overline{X}-\mu)}{S}\sim t_{n-1}$ for $X_i\sim \mathcal{N}(\mu, \sigma^2)$

$\sigma^2=\frac{v}{v-2}$ for $v>2$, $\infty$ for $1<v\le 2$

$f(t)=\frac{\Gamma[(n + 1) / 2]}{\sqrt{n\pi}\Gamma(n/2)}\left(1 + \frac{t^2}{n}\right)^{-\frac{n + 1}{2}}$

\textbf{$F$-Distribution}

$F(m, n) = \frac{U/m}{V/n}, U\sim\chi_m^2, V\sim \chi_n^2$

$f(w)=\frac{\Gamma\left(\frac{n+m}{2}\right)}{\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}\cdot\left(\frac{m}{n}\right)^{\frac{m}{2}}\cdot w^{\frac{m}{2}-1}\cdot\left(1+\frac{m}{n}w\right)^{-\frac{m+n}{2}}$

$\mu=\frac{n}{n-2}$ for $n>2$

$\sigma^2=\frac{2n^2(m+n-2)}{m(n-2)^2(n-4)}$ for $n>4$

\subsection{MGF}

$M(X)=\mathbb{E}\left[e^{tX}\right]$

$M^{(m)}(X)=\mathbb{E}\left[X^m\right]$

\begin{tabular}{|c|c|c|}
\hline
\textbf{Distribution} & \textbf{MGF} & \textbf{PMF/PDF}\\ \hline
$\mathrm{Bernoulli}(p)$ & $pe^t + 1-p$ & $p(1)=p$ \\ \hline
$\mathrm{Binomial}(n, p)$ & $(1-p + pe^t)^n$&$\binom{n}{k}p^k(1-p)^{n-k}$\\ \hline
$\mathrm{Poisson}(\lambda)$ & $e^{\lambda(e^t - 1)}$ &$p(k)=\frac{\lambda^k}{k!}e^{-\lambda}$\\ \hline
$\mathrm{Geo}(p)$ & $\frac{pe^t}{1-(1-p)e^t}$ & $(1-p)^{k-1}p$ \\ \hline
$\mathcal{N}(\mu, \sigma^2)$ & $e^{t\mu + \frac{1}{2}\sigma^2 t^2}$ &$\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$  \\ \hline
$\mathrm{Exp}(\lambda)$ & $\frac{\lambda}{\lambda - t}$ & $\lambda e^{-\lambda x}$ \\ \hline
$\Gamma(\alpha, \beta)$ & $(1 - \beta t)^{-\alpha}$ & $\frac{1}{\beta^k\Gamma(k)}x^{k-1}e^{-\frac{x}{\beta}}$ \\ \hline
$\chi^2_k$ & $(1 - 2t)^{-\frac{k}{2}}$ &$\frac{1}{2^{\frac{k}{2}}\Gamma\left(\frac{k}{2}\right)}x^{\frac{k}{2}-1}e^{-\frac{x}{2}}$\\ \hline
\end{tabular}

\subsection{Central Limit Theorem}

\textbf{Markov's inequality}: $\mathbb{P}\mathrm{r}\left\{X\ge t\right\}\le\frac{\mathbb{E}(X)}{t}$，要求是 $X\ge 0, t>0$

\textbf{Chebyshev's Inequality}：$\mathbb{P}\mathrm{r}\{|X-\mathbb{E}(X)|\ge t\}\le\frac{\mathrm{Var}(X)}{t^2}$

$\mathbb{P}\mathrm{r}\{|X-\mathbb{E}(X)|\ge k\sigma\}\le\frac{1}{k^2}$

\textbf{Weak LLN}: $\lim_{n\to\infty}\mathbb{P}\mathrm{r}\left\{\left|\overline{X}_n-\mu\right|>\epsilon\right\}=0$

\textbf{Strong LLN}: $\mathbb{P}\mathrm{r}\left\{\lim_{n\to\infty}\overline{X}_n=\mu\right\}=1$

\textbf{CLT}: $\lim_{n\to\infty}\mathbb{P}\mathrm{r}\left\{\frac{S_n-n\mu}{\sigma\sqrt{n}}\le x\right\}=\Phi(x)$

\section{Estimation}

\subsection{Method of Moments (MME)}

$\mathbb{E}(X_1^j)=\mu_j$

$\mu_j=g_j(\boldsymbol{\theta})$

$\theta_k=h_k(\boldsymbol{\mu})$

\subsection{Maximum Likelihood (MLE)}

$L(\boldsymbol{x}\mid \boldsymbol{\theta})=\prod_{i=1}^n f(x_i\mid \boldsymbol{\theta})$

Standard conditions:
\begin{enumerate}
	\item $L(\theta)>0$ for all $\theta\in(a, b)$
	\item $\frac{\partial L(\theta)}{\partial\theta}$ exists for all $\theta\in (a, b)$
	\item $\lim_{\theta\to a^+}L(\theta)=\lim_{\theta\to b^-}L(\theta)=0$
\end{enumerate}

\subsection{Estimate an Estimator}

$\mathbf{Bias}(\hat\theta)=\mathbb{E}_\theta(\hat\theta)-\theta$

unbiased: $\mathrm{Bias}(\hat\theta)=0$

\textbf{Standard Error}: $\mathrm{SE}(\hat\theta)=\sqrt{\mathrm{Var}(\hat{\theta})}$

Rule of thumb: 如果 sample 足够大，$\theta\in[\hat{\theta}-\mathrm{SE}(\hat{\theta}),\hat{\theta}+\mathrm{SE}(\hat{\theta})]$ 是 $70\%$，$\theta\in[\hat{\theta}-2\cdot\mathrm{SE}(\hat{\theta}),\hat{\theta}+2\cdot\mathrm{SE}(\hat{\theta})]$ 是 $95\%$

\textbf{Mean Squared Error}: $\mathrm{MSE}(\hat{\theta})=\mathbb{E}\left[\left(\hat{\theta}-\theta\right)^2\right]$

$\mathrm{MSE}(\hat{\theta})=\mathrm{Bias}(\hat{\theta})^2+\mathrm{Var}(\hat\theta)=\mathrm{Bias}(\hat{\theta})^2+\mathrm{SE}(\hat\theta)^2$

Bias 是要准，SE 是要快，MSE 是成年人我都要

如何走向人生巅峰：$\widehat{\theta'_n}=\frac{\theta}{\mathbb{E}\left(\widehat{\theta_n}\right)}\widehat{\theta_n}$

\textbf{Consistent}: $\forall\varepsilon>0\Rightarrow\lim_{n\to\infty}\mathbb{P}(|\hat{\theta_n}-\theta|>\varepsilon)=0$

咋证： $\lim_{n\to\infty}\mathrm{Bias}(\hat{\theta_n})=0\land\lim_{n\to\infty}\mathrm{Var}(\hat{\theta_n})=0$

MME 只要是 $h$ 连续一定是 consistent 嘟

\subsection{Fisher Information}

\textbf{Log-likelihood function}: $\ell=\log L$

\textbf{Score function}: $V(\boldsymbol{X}\mid\theta)=\frac{\partial}{\partial\theta}\ell(\boldsymbol{X}\mid\theta)$

\textbf{Fisher Information}: $I_{\boldsymbol{X}}(\theta)=\mathbb{E}\left[V(\boldsymbol{X}\mid\theta)^2\right]$

Condition (*) （离散同理，换成 $\sum$）:

$\int_{-\infty}^{\infty}\frac{\partial}{\partial\theta}f(x\mid\theta)\mathrm{d}x=\frac{\partial}{\partial\theta}\int_{-\infty}^{\infty}f(x\mid\theta)\mathrm{d}x=0$

满足 (*) 这个可以推：$\mathbb{E}(V)=0\land \mathrm{Var}(V)=I$

\textbf{Fisher Info Alternative Formula}

$I_{\boldsymbol{X}}(\theta)=nI_{X_1}(\theta)=-n\cdot\mathbb{E}[\frac{\partial^2}{\partial\theta^2}\log L(X_1\mid\theta)]$

证明是首先需要注意到

$\frac{\partial}{\partial\theta}f(x\mid\theta)=\left[\frac{\partial}{\partial\theta}\log f(x\mid\theta)\right]f(x\mid\theta)$ 

然后把 $0=\frac{\partial}{\partial\theta}\int f(x\mid\theta)\mathrm{d}x=\int\left[\frac{\partial}{\partial\theta}\log f(x\mid\theta)\right]f(x\mid\theta)\mathrm{d}x$ 两边再求个偏导

\subsection{Cramér-Rao Lower Bound (CRLB)}

条件：$\frac{\partial}{\partial\theta}\left[\int_{-\infty}^{\infty}\cdots\int_{-\infty}^{\infty}h(\boldsymbol{x})f(\boldsymbol{x}\mid\theta)\mathrm{d}x_1\cdots\mathrm{d}x_n\right]=\left[\int_{-\infty}^{\infty}\cdots\int_{-\infty}^{\infty}h(\boldsymbol{x})\frac{\partial}{\partial\theta}f(\boldsymbol{x}\mid\theta)\mathrm{d}x_1\cdots\mathrm{d}x_n\right]$, For all $h$ with $\mathbb{E}(|h(\boldsymbol{X})|)<\infty$

$\mathrm{Var}(\hat{\theta})\ge \frac{\left[\frac{\partial}{\partial\theta}\mathbb{E}(T)\right]^2}{\mathbb{E}\left[\left(\frac{\partial}{\partial\theta}\log f(\boldsymbol{X}\mid\theta)\right)^2	\right]}$

如果 $\hat{\theta}$ 是 unbiased 的，那我们有 $\mathrm{Var}(\hat{\theta})\ge\frac{1}{nI_{X_1}(\theta)}$

\textbf{efficient} 1. unbiased, 2. $\mathrm{Var}(\hat{\theta})=\frac{1}{nI_{X_1}(\theta)}$

\subsection{Asymptotic Normality}

\textbf{Regularity Conditions} ($\hat{\theta}$ 是 MLE)
\begin{enumerate}
	\item $\frac{\partial^3}{\partial\theta^3}f(x\mid\theta)$ exists and continuous
	\item $\exists (a, b)\subseteq S, \theta_0\in(a, b)$
	\item (support) ${x\in\mathbb{R}: f(x\mid\theta)>0}$ is the same $\forall\theta$
\end{enumerate}

不满足：$\mathrm{Bernoulli}(p)$: 找不到区间；$U(0, b)$: 不 support

$\sqrt{nI_{X_1}(\theta_0)}(\hat{\theta}-\theta_0)\sim\mathcal{N}(0, 1)$

\subsection{Confidence Intervals}

\textbf{upper percentage point}: $z_\alpha$, $\mathbb{P}(X>z_\alpha)=\alpha$

$\forall\theta_0\in S, \mathbb{P}(L\le \theta_0\le U)=1-\alpha$

exact $100(1-\alpha)\%$ confidence interval for $\theta$

$1-\alpha$: \textbf{confidence level}

需要注意的是 $L$ 和 $R$ 才是尊 Random Var

\textbf{Pivotal Quantity}: The \textbf{distribution} of $Q(\boldsymbol{X}, \theta)$ does not depend on any unknown parameter

如果 $X_i\sim N(\mu, 1)$，$\overline{X}$ 是不可以的（因为 $\mu$ 不知道），但是 $\sqrt{n}(\overline{X}-\mu)$ 是可以的

How to prove: PDF/CDF/MGF 都可以

\textbf{asymptotically pivotal quantity}: $Q_{n\to\infty}\to\Psi$

approximate / large sample confidence intervals

$\left[\hat{\theta}-\frac{z_{\alpha/2}}{\sqrt{nI(\hat{\theta})}}, \hat{\theta}+\frac{z_{\alpha/2}}{\sqrt{nI(\hat{\theta})}}\right]$ to approx $100(1-\alpha)\%$

\section{Hypothesis Testing}

如果 $H_0$ 发生了，那 $\boldsymbol{X}$ 发生的概率有多小

p-value $p=\mathbb{P}(T(\boldsymbol{X})\ge s\mid H_0)$

significance level: $\alpha$, critical value: $t(\alpha)$

$p<\alpha\Leftrightarrow s>t(\alpha)\Leftrightarrow\text{reject } H_0$

算significance level：

$T$ 越大越 against $H_0$：$\max_s(\mathbb{P}(T(\boldsymbol{X})\ge s\mid H_0)\ge\alpha)$

$T$ 越小越 against $H_0$：$\min_s(\mathbb{P}(T(\boldsymbol{X})\le s\mid H_0)\ge\alpha)$

\textbf{Neyman-Pearson tests}

Parameter Space: $\Omega=\Omega_0\cup\Omega_1$

$H_0: \theta\in\Omega_0, H_1: \theta\in\Omega_1$

如果 $|\Omega_0|=1$ 叫 simple hypothesis，否则 composite

我其实想要的是 $H_1$：
\begin{enumerate}
	\item rejecting the $H_0$ in favor of the $H_1$.
	\item there is not enough evidence to support the $H_1$.
\end{enumerate}

Type I error ($\alpha$): $H_0$ 本不该被 reject，却 reject 了，FP

Type I error ($\beta$): $H_0$ 该被 rej，却没 rej, FN

rejection region $R\subseteq \mathbb{R}^n$: 样本在这里就选 $H_1$

\textbf{size} $\alpha$ 所有 $H_0$ 成立的情况下，rej 的最大可能性

$\sup_{\theta\in\Omega_0}\mathbb{P}(H_0 \text{ is rejected}\mid\theta)=\alpha$

\textbf{level} $H_0$ 成立，rej 的可能性小于等于他 $\sup\le\alpha$

\textbf{power} $H_1$ 成立，有多大可能性拒绝 $H_0$

$\mathrm{Power}(\theta)=\mathbb{P}(H_0\text{ rejected}\mid\theta\in\Omega_1)=1-\beta(\theta)$

\textbf{Neyman-Pearson Lemma}

simple vs simple

\textbf{Likelihood ratio} $\Lambda(\boldsymbol{x})=\frac{L(\boldsymbol{x}\mid\theta_0)}{L(\boldsymbol{x}\mid\theta_1)}$

rejection region $R = \{\boldsymbol{x}\in\mathbb{R}^n: \Lambda\le t\}$

\textbf{Monotone Likelihood Ratio (MLR)}

对于 $\theta<\theta'$，存在 $T(\boldsymbol{x})$ 使得 $\frac{p_{\theta'}(x)}{p_\theta(x)}$ 对 $T(\boldsymbol{x})$ 是不降的

simple vs composite

uniformly most powerful (UMP)

满足 MLR，UMP test 存在，$\sup$ 在 $\theta=\theta_0$ 时候取到

如果 $(L, U)$ 是一个 $100(1-\alpha)\%$ 的 confidence interval，那么 $\text{reject }H_0: 0=\theta_0\Leftrightarrow\theta_0\notin(L, U)$ 是 $\alpha$ size 的

反过来也可以说

\end{multicols}

\end{document}
